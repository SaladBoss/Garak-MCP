# Example environment variables for Garak MCP

# --- Ollama ---
# The base URL for the Ollama API (used for generating completions)
OLLAMA_API_URL=http://localhost:11434/api/generate
# The URL for listing installed Ollama models (tags)
OLLAMA_TAGS_URL=http://localhost:11434/api/tags

# --- OpenAI ---
# Your OpenAI API key
OPENAI_API_KEY=sk-...
# Comma-separated list of OpenAI model names to use
OPENAI_MODELS=gpt-3.5-turbo,gpt-4,gpt-4-turbo-preview

# --- HuggingFace ---
# Your HuggingFace API key
HUGGINGFACE_API_KEY=hf_...
# Comma-separated list of HuggingFace model names to use
HUGGINGFACE_MODELS=bigscience/bloom,facebook/opt-1.3b,meta-llama/Llama-2-7b-chat-hf,meta-llama/Llama-2-13b-chat-hf

# --- GGML ---
# Comma-separated list of GGML model names to use
GGML_MODELS=llama-2-7b,ggml-model,/path/to/model1.gguf,/path/to/model2.gguf

# --- Custom REST (e.g., LiteLLM, vLLM, OpenAI-compatible) ---
# The base URL for your custom REST API endpoint
OPENAI_LIKE_API_URL=http://localhost:4000
# API key for your custom REST endpoint (if needed)
OPENAI_LIKE_API_KEY=sk-...
# Default model name for custom REST endpoint (if /v1/models is not supported)
OPENAI_LIKE_MODEL=my-model

# --- Misc ---
# Number of parallel attempts for Garak attacks (default: 1)
PARALLEL_ATTEMPTS=1

# --- Notes ---
# The config/ollama.json file is used as a template for Garak's REST generator.
# The server will update the model name, API URL, and headers dynamically based on your environment variables.
# You should NOT delete config/ollama.json. It is required as a template for generating temporary config files for Garak REST attacks.